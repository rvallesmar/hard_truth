{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb64ea4d",
   "metadata": {},
   "source": [
    "This notebook will contain the process of extracting the text embeddings to build the hard truth, and the testing of that implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91247b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from src.nlp_models import HuggingFaceEmbeddings\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1f4f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Setup paths ---\n",
    "BASE_DIR = os.getcwd()\n",
    "SRC_DIR = f'{BASE_DIR}/src'\n",
    "OUTPUT_DIR = f'{BASE_DIR}/outputs'\n",
    "\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- Load environment variables ---\n",
    "load_dotenv(f'{BASE_DIR}/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c876820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "SEARCH_QUERY = \"2024 Champions League Final\"\n",
    "LANGUAGE = \"en\"\n",
    "TOTAL_ARTICLES = 100\n",
    "PAGE_SIZE = 5\n",
    "TOPIC_LABEL = \"champions+league+2024\"\n",
    "PUBLISHED_AFTER = \"2024-01-01\"\n",
    "\n",
    "ARTICLES_CSV = f'{OUTPUT_DIR}/articles.csv'\n",
    "EMBEDDED_CSV = f'{OUTPUT_DIR}/embedded_articles.csv'\n",
    "SCORED_CSV = f'{OUTPUT_DIR}/articles_scored.csv'\n",
    "GROUND_TRUTH_TXT = f'{OUTPUT_DIR}/ground_truth.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c51495",
   "metadata": {},
   "source": [
    "Part 1: Fetch articles and store them to a dataframe object\n",
    "===\n",
    "The articles where downloaded using the NewsAPI resource available online. We downloaded a total of 100 articles saved in the ```outputs/articles.csv``` location.\n",
    "\n",
    "If you wish to download another set of articles you would have to run the code seen below, but you'd have to obtain a new API key from the resource [available here](https://newsapi.org/) and store that key in the variable ```THENEWSAPI_KEY``` in your .env file.\n",
    "\n",
    "```python\n",
    "print(\"Fetching articles...\")\n",
    "articles = fetch_articles(\n",
    "    query=SEARCH_QUERY,\n",
    "    language=LANGUAGE,\n",
    "    total_articles=TOTAL_ARTICLES,\n",
    "    page_size=PAGE_SIZE,\n",
    "    topic_label=TOPIC_LABEL,\n",
    "    published_after=PUBLISHED_AFTER\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987c447",
   "metadata": {},
   "source": [
    "Now you can see that the structure of the dataframe containing our article data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712943cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>source</th>\n",
       "      <th>published_at</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0cd1f952-eb81-44ed-9792-5c854acfaeb4</td>\n",
       "      <td>Date confirmed for CAF Champions League quarte...</td>\n",
       "      <td>CAF has announced the date and venue for the q...</td>\n",
       "      <td>thesouthafrican.com</td>\n",
       "      <td>2025-02-05T09:49:17.000000Z</td>\n",
       "      <td>https://www.thesouthafrican.com/sport/soccer/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e3f890d4-4637-4dde-a45d-89c0f61a9046</td>\n",
       "      <td>Champions League final, Premier League race: M...</td>\n",
       "      <td>Open Extended Reactions\\n\\nWith PSG and Boruss...</td>\n",
       "      <td>espn.co.uk</td>\n",
       "      <td>2024-05-02T15:35:23.000000Z</td>\n",
       "      <td>https://www.espn.co.uk/football/story/_/id/400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83888beb-8b74-4e0e-8b46-97541b03ca31</td>\n",
       "      <td>Champions League final, Premier League race: M...</td>\n",
       "      <td>Open Extended Reactions\\n\\nWith PSG and Boruss...</td>\n",
       "      <td>espn.com</td>\n",
       "      <td>2024-05-02T12:31:53.000000Z</td>\n",
       "      <td>https://www.espn.com/soccer/story/_/id/4005714...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             article_id  \\\n",
       "0  0cd1f952-eb81-44ed-9792-5c854acfaeb4   \n",
       "1  e3f890d4-4637-4dde-a45d-89c0f61a9046   \n",
       "2  83888beb-8b74-4e0e-8b46-97541b03ca31   \n",
       "\n",
       "                                               title  \\\n",
       "0  Date confirmed for CAF Champions League quarte...   \n",
       "1  Champions League final, Premier League race: M...   \n",
       "2  Champions League final, Premier League race: M...   \n",
       "\n",
       "                                                body               source  \\\n",
       "0  CAF has announced the date and venue for the q...  thesouthafrican.com   \n",
       "1  Open Extended Reactions\\n\\nWith PSG and Boruss...           espn.co.uk   \n",
       "2  Open Extended Reactions\\n\\nWith PSG and Boruss...             espn.com   \n",
       "\n",
       "                  published_at  \\\n",
       "0  2025-02-05T09:49:17.000000Z   \n",
       "1  2024-05-02T15:35:23.000000Z   \n",
       "2  2024-05-02T12:31:53.000000Z   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.thesouthafrican.com/sport/soccer/c...  \n",
       "1  https://www.espn.co.uk/football/story/_/id/400...  \n",
       "2  https://www.espn.com/soccer/story/_/id/4005714...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pd.read_csv(ARTICLES_CSV)\n",
    "df_articles.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091b589",
   "metadata": {},
   "source": [
    "Part 2: Generate text embeddings\n",
    "===\n",
    "#TODO add text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1ed590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model moved to device: cpu\n",
      "Model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbeddings(path=str(ARTICLES_CSV), save_path=str(OUTPUT_DIR))\n",
    "embeds_df = embedder.get_embedding_df(column='body', directory=str(OUTPUT_DIR), file='embedded_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c56ac",
   "metadata": {},
   "source": [
    "Now that we have the embeddings, we procosses them and store them into our same dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdd55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv(EMBEDDED_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e85eacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <td>0cd1f952-eb81-44ed-9792-5c854acfaeb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Date confirmed for CAF Champions League quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>CAF has announced the date and venue for the q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>thesouthafrican.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>published_at</th>\n",
       "      <td>2025-02-05T09:49:17.000000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://www.thesouthafrican.com/sport/soccer/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings</th>\n",
       "      <td>[-0.15082290768623352, 0.014091070741415024, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              0\n",
       "article_id                 0cd1f952-eb81-44ed-9792-5c854acfaeb4\n",
       "title         Date confirmed for CAF Champions League quarte...\n",
       "body          CAF has announced the date and venue for the q...\n",
       "source                                      thesouthafrican.com\n",
       "published_at                        2025-02-05T09:49:17.000000Z\n",
       "url           https://www.thesouthafrican.com/sport/soccer/c...\n",
       "embeddings    [-0.15082290768623352, 0.014091070741415024, -..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_embeddings.shape)\n",
    "df_embeddings.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85f2b1",
   "metadata": {},
   "source": [
    "The shape of our new dataframe object becomes 98 by 390, because now for each of the 98 articles, we added 1 column per vector in our original embeddings that we generated for our text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18a154",
   "metadata": {},
   "source": [
    "Part 3: Extract ground truth from all articles\n",
    "===\n",
    "#TODO add text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3089a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e200d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Processing Article 1----------\n",
      "----------Processing Article 2----------\n",
      "----------Processing Article 3----------\n",
      "----------Processing Article 4----------\n",
      "----------Processing Article 5----------\n",
      "----------Processing Article 6----------\n",
      "----------Processing Article 7----------\n",
      "----------Processing Article 8----------\n",
      "----------Processing Article 9----------\n",
      "----------Processing Article 10----------\n",
      "----------Processing Article 11----------\n",
      "----------Processing Article 12----------\n",
      "----------Processing Article 13----------\n",
      "----------Processing Article 14----------\n",
      "----------Processing Article 15----------\n",
      "----------Processing Article 16----------\n",
      "----------Processing Article 17----------\n",
      "----------Processing Article 18----------\n",
      "----------Processing Article 19----------\n",
      "----------Processing Article 20----------\n",
      "----------Processing Article 21----------\n",
      "----------Processing Article 22----------\n",
      "----------Processing Article 23----------\n",
      "----------Processing Article 24----------\n",
      "----------Processing Article 25----------\n",
      "----------Processing Article 26----------\n",
      "----------Processing Article 27----------\n",
      "----------Processing Article 28----------\n",
      "----------Processing Article 29----------\n",
      "----------Processing Article 30----------\n",
      "----------Processing Article 31----------\n",
      "----------Processing Article 32----------\n",
      "----------Processing Article 33----------\n",
      "----------Processing Article 34----------\n",
      "----------Processing Article 35----------\n",
      "----------Processing Article 36----------\n",
      "----------Processing Article 37----------\n",
      "----------Processing Article 38----------\n",
      "----------Processing Article 39----------\n",
      "----------Processing Article 40----------\n",
      "----------Processing Article 41----------\n",
      "----------Processing Article 42----------\n",
      "----------Processing Article 43----------\n",
      "----------Processing Article 44----------\n",
      "----------Processing Article 45----------\n",
      "----------Processing Article 46----------\n",
      "----------Processing Article 47----------\n",
      "----------Processing Article 48----------\n",
      "----------Processing Article 49----------\n",
      "----------Processing Article 50----------\n",
      "----------Processing Article 51----------\n",
      "----------Processing Article 52----------\n",
      "----------Processing Article 53----------\n",
      "----------Processing Article 54----------\n",
      "----------Processing Article 55----------\n",
      "----------Processing Article 56----------\n",
      "----------Processing Article 57----------\n",
      "----------Processing Article 58----------\n",
      "----------Processing Article 59----------\n",
      "----------Processing Article 60----------\n",
      "----------Processing Article 61----------\n",
      "----------Processing Article 62----------\n",
      "----------Processing Article 63----------\n",
      "----------Processing Article 64----------\n",
      "----------Processing Article 65----------\n",
      "----------Processing Article 66----------\n",
      "----------Processing Article 67----------\n",
      "----------Processing Article 68----------\n",
      "----------Processing Article 69----------\n",
      "----------Processing Article 70----------\n",
      "----------Processing Article 71----------\n",
      "----------Processing Article 72----------\n",
      "----------Processing Article 73----------\n",
      "----------Processing Article 74----------\n",
      "----------Processing Article 75----------\n",
      "----------Processing Article 76----------\n",
      "----------Processing Article 77----------\n",
      "----------Processing Article 78----------\n",
      "----------Processing Article 79----------\n",
      "----------Processing Article 80----------\n",
      "----------Processing Article 81----------\n",
      "----------Processing Article 82----------\n",
      "----------Processing Article 83----------\n",
      "----------Processing Article 84----------\n",
      "----------Processing Article 85----------\n",
      "----------Processing Article 86----------\n",
      "----------Processing Article 87----------\n",
      "----------Processing Article 88----------\n",
      "----------Processing Article 89----------\n",
      "----------Processing Article 90----------\n",
      "----------Processing Article 91----------\n",
      "----------Processing Article 92----------\n",
      "----------Processing Article 93----------\n",
      "----------Processing Article 94----------\n",
      "----------Processing Article 95----------\n",
      "----------Processing Article 96----------\n",
      "----------Processing Article 97----------\n",
      "----------Processing Article 98----------\n",
      "----------Processing Article 99----------\n",
      "----------Processing Article 100----------\n",
      "----------Processing Article 101----------\n",
      "----------Processing Article 102----------\n",
      "\n",
      "--- Common Details Found ---\n",
      "- place (Found in 28 articles)\n",
      "- who (Found in 61 articles)\n",
      "- you (Found in 38 articles)\n",
      "- us (Found in 21 articles)\n",
      "- real madrid (Found in 41 articles)\n",
      "- wednesday (Found in 24 articles)\n",
      "- they (Found in 61 articles)\n",
      "- borussia dortmund (Found in 28 articles)\n",
      "- may (Found in 26 articles)\n",
      "- we (Found in 46 articles)\n",
      "- that (Found in 62 articles)\n",
      "- psg (Found in 28 articles)\n",
      "- manchester city (Found in 36 articles)\n",
      "- what (Found in 34 articles)\n",
      "- barcelona (Found in 45 articles)\n",
      "- the competition (Found in 25 articles)\n",
      "- the trophy (Found in 20 articles)\n",
      "- the round (Found in 23 articles)\n",
      "- the champions league final (Found in 20 articles)\n",
      "- i (Found in 36 articles)\n",
      "- the champions league (Found in 60 articles)\n",
      "- it (Found in 71 articles)\n",
      "- bayern munich (Found in 41 articles)\n",
      "- which (Found in 40 articles)\n",
      "- he (Found in 29 articles)\n",
      "- them (Found in 37 articles)\n",
      "- saturday (Found in 21 articles)\n",
      "- madrid (Found in 35 articles)\n",
      "- the game (Found in 21 articles)\n",
      "- home (Found in 23 articles)\n",
      "- liverpool (Found in 29 articles)\n",
      "- munich (Found in 28 articles)\n",
      "- arsenal (Found in 21 articles)\n",
      "- this (Found in 27 articles)\n",
      "- london (Found in 22 articles)\n",
      "- the team (Found in 21 articles)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "ground_truth = utils.get_ground_truth(ARTICLES_CSV, nlp)\n",
    "\n",
    "with open(GROUND_TRUTH_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eef1fb",
   "metadata": {},
   "source": [
    "Part 4: Create the text embeddings for the ground truth\n",
    "===\n",
    "#TODO add text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d7e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we transform our ground truth into a text embedding vector\n",
    "\n",
    "# we get our ground truth as a single string\n",
    "ground_truth_list = list()\n",
    "with open(GROUND_TRUTH_TXT, 'r') as f:\n",
    "    for word in f:\n",
    "        ground_truth_list.append(word.strip())\n",
    "\n",
    "ground_truth = \" \".join(ground_truth_list)\n",
    "\n",
    "ground_truth_embedding = HuggingFaceEmbeddings.get_single_embedding(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d3c6a",
   "metadata": {},
   "source": [
    "Part 5: Compare the similarity between each of the embeddings to the Ground Truth\n",
    "===\n",
    "#TODO add text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2018b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.41755040577605784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will be using cosine similarity to evaluate the similarity between each article and the previously\n",
    "# built ground truth\n",
    "df_scored = utils.compare_articles_to_ground_truth(df_embeddings, ground_truth_embedding)\n",
    "\n",
    "# df_scored.to_csv(SCORED_CSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
